{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8c0b996-7118-4356-8a58-8c9638d7a89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision as tv\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c20b0c5-0294-4e95-aeea-38f7dc989fa1",
   "metadata": {},
   "source": [
    "## Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fad2371-5aeb-4079-8b69-8c0d1c0b85e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# на таких данных GPU на M1 работает медленнее, потому работаем на CPU.\n",
    "# if torch.backends.mps.is_available():\n",
    "#     device = torch.device(\"mps\")\n",
    "# else:\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b34fc7a-9490-4b05-9d15-1ec8b3e82602",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=256\n",
    "train_dataset = tv.datasets.FashionMNIST('.', train=True, transform=tv.transforms.ToTensor(), download=True)\n",
    "test_dataset = tv.datasets.FashionMNIST('.', train=False, transform=tv.transforms.ToTensor(), download=True)\n",
    "train = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "test = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14868e4e-3059-4013-a330-0bf3b7bf4f47",
   "metadata": {},
   "source": [
    "## Просмотр данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6a994ea5-bee3-44b4-bfbe-4f0109dfe477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5a6359bb-813d-423a-8385-497ef43f0b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = train_dataset[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0a70aaa1-c657-4b33-82eb-a0a71f2a6cb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "plt.imshow(image.squeeze(), cmap='gray') # Use .squeeze() to remove the single color channel dimension\n",
    "plt.title(f\"Label: {class_names[label]}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37b861c-8b8b-4662-8d16-2e78293a1373",
   "metadata": {},
   "source": [
    "## Модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f2a7d469-2b0e-43cf-bf16-1220169212ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(784, 256),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(256, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7503ec38-eab6-4841-8992-a3a90a50b91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74d0fb17-60c8-4e53-a951-8381beee042f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.nn.CrossEntropyLoss()\n",
    "trainer = torch.optim.SGD(model.parameters(), lr=.01)\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9cd7c1e8-a3b5-4e47-9551-cac653a8659d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    for ep in range(num_epochs):\n",
    "        train_iters, train_passed  = 0, 0\n",
    "        train_loss, train_acc = 0., 0.\n",
    "        start=time.time()\n",
    "        \n",
    "        model.train()\n",
    "        for X, y in train:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            trainer.zero_grad()\n",
    "            y_pred = model(X)\n",
    "            l = loss(y_pred, y)\n",
    "            l.backward()\n",
    "            trainer.step()\n",
    "            train_loss += l.item()\n",
    "            train_acc += (y_pred.argmax(dim=1) == y).sum().item()\n",
    "            train_iters += 1\n",
    "            train_passed += len(X)\n",
    "        \n",
    "        test_iters, test_passed  = 0, 0\n",
    "        test_loss, test_acc = 0., 0.\n",
    "        model.eval()\n",
    "        for X, y in test:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            y_pred = model(X)\n",
    "            l = loss(y_pred, y)\n",
    "            test_loss += l.item()\n",
    "            test_acc += (y_pred.argmax(dim=1) == y).sum().item()\n",
    "            test_iters += 1\n",
    "            test_passed += len(X)\n",
    "            \n",
    "        print(\"ep: {}, taked: {:.3f}, train_loss: {:.3f}, train_acc: {:.3f}, test_loss: {:.3f}, test_acc: {:.3f}\".format(\n",
    "            ep, time.time() - start, train_loss / train_iters, train_acc / train_passed,\n",
    "            test_loss / test_iters, test_acc / test_passed)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "88942a38-4c9e-4fad-bb79-642c13ea71a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep: 0, taked: 2.058, train_loss: 1.757, train_acc: 0.557, test_loss: 1.299, test_acc: 0.647\n",
      "ep: 1, taked: 2.011, train_loss: 1.083, train_acc: 0.677, test_loss: 0.950, test_acc: 0.679\n",
      "ep: 2, taked: 2.013, train_loss: 0.866, train_acc: 0.713, test_loss: 0.819, test_acc: 0.713\n",
      "ep: 3, taked: 2.010, train_loss: 0.769, train_acc: 0.744, test_loss: 0.746, test_acc: 0.739\n",
      "ep: 4, taked: 2.005, train_loss: 0.709, train_acc: 0.764, test_loss: 0.697, test_acc: 0.758\n",
      "ep: 5, taked: 2.045, train_loss: 0.666, train_acc: 0.780, test_loss: 0.660, test_acc: 0.772\n",
      "ep: 6, taked: 2.031, train_loss: 0.633, train_acc: 0.791, test_loss: 0.632, test_acc: 0.782\n",
      "ep: 7, taked: 2.029, train_loss: 0.607, train_acc: 0.799, test_loss: 0.610, test_acc: 0.789\n",
      "ep: 8, taked: 2.097, train_loss: 0.586, train_acc: 0.806, test_loss: 0.591, test_acc: 0.796\n",
      "ep: 9, taked: 2.063, train_loss: 0.568, train_acc: 0.811, test_loss: 0.576, test_acc: 0.802\n"
     ]
    }
   ],
   "source": [
    "train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9abf99-566d-466b-a4be-671a28da2d33",
   "metadata": {},
   "source": [
    "## Попробуем Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "132c84dc-2f1e-42d9-be8a-9ddd1d93186f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(784, 256),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(256, 10)\n",
    ")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "22e0b859-249f-4cb2-a13d-f1fc3dedb3af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep: 0, taked: 2.176, train_loss: 0.541, train_acc: 0.809, test_loss: 0.449, test_acc: 0.834\n",
      "ep: 1, taked: 2.111, train_loss: 0.384, train_acc: 0.860, test_loss: 0.409, test_acc: 0.854\n",
      "ep: 2, taked: 2.132, train_loss: 0.347, train_acc: 0.873, test_loss: 0.389, test_acc: 0.860\n",
      "ep: 3, taked: 2.122, train_loss: 0.330, train_acc: 0.879, test_loss: 0.404, test_acc: 0.858\n",
      "ep: 4, taked: 2.125, train_loss: 0.316, train_acc: 0.883, test_loss: 0.399, test_acc: 0.860\n",
      "ep: 5, taked: 2.117, train_loss: 0.304, train_acc: 0.888, test_loss: 0.394, test_acc: 0.862\n",
      "ep: 6, taked: 2.141, train_loss: 0.292, train_acc: 0.891, test_loss: 0.384, test_acc: 0.865\n",
      "ep: 7, taked: 2.123, train_loss: 0.286, train_acc: 0.893, test_loss: 0.395, test_acc: 0.862\n",
      "ep: 8, taked: 2.123, train_loss: 0.278, train_acc: 0.896, test_loss: 0.388, test_acc: 0.867\n",
      "ep: 9, taked: 2.126, train_loss: 0.270, train_acc: 0.899, test_loss: 0.401, test_acc: 0.865\n"
     ]
    }
   ],
   "source": [
    "trainer = torch.optim.Adam(model.parameters(), lr=.01)\n",
    "train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf36f74-7348-40a2-847c-f1f83ae7506d",
   "metadata": {},
   "source": [
    "Переход на adam повысил качество обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821f6b73-e9e2-44ac-add2-03a5793ceb41",
   "metadata": {},
   "source": [
    "## Попробуем больше слоев и сразу batch norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c32844a2-c077-4578-b998-fc2a7ab434f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(784, 512),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.BatchNorm1d(512),\n",
    "    torch.nn.Linear(512, 256),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.BatchNorm1d(256),\n",
    "    torch.nn.Linear(256, 128),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.BatchNorm1d(128),\n",
    "    torch.nn.Linear(128, 10)\n",
    ")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "47e57bb4-87ca-4d3a-a260-a37848cc30b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep: 0, taked: 2.888, train_loss: 0.468, train_acc: 0.829, test_loss: 0.434, test_acc: 0.839\n",
      "ep: 1, taked: 2.849, train_loss: 0.371, train_acc: 0.864, test_loss: 0.389, test_acc: 0.857\n",
      "ep: 2, taked: 2.892, train_loss: 0.336, train_acc: 0.876, test_loss: 0.424, test_acc: 0.844\n",
      "ep: 3, taked: 2.862, train_loss: 0.312, train_acc: 0.884, test_loss: 0.423, test_acc: 0.851\n",
      "ep: 4, taked: 2.873, train_loss: 0.298, train_acc: 0.889, test_loss: 0.404, test_acc: 0.863\n",
      "ep: 5, taked: 2.894, train_loss: 0.282, train_acc: 0.896, test_loss: 0.409, test_acc: 0.867\n",
      "ep: 6, taked: 2.879, train_loss: 0.273, train_acc: 0.898, test_loss: 0.387, test_acc: 0.866\n",
      "ep: 7, taked: 2.970, train_loss: 0.258, train_acc: 0.905, test_loss: 0.393, test_acc: 0.868\n",
      "ep: 8, taked: 3.047, train_loss: 0.248, train_acc: 0.907, test_loss: 0.418, test_acc: 0.872\n",
      "ep: 9, taked: 2.904, train_loss: 0.239, train_acc: 0.911, test_loss: 0.410, test_acc: 0.856\n"
     ]
    }
   ],
   "source": [
    "trainer = torch.optim.Adam(model.parameters(), lr=.01)\n",
    "train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88011148-6825-4087-8521-313ed64ce646",
   "metadata": {},
   "source": [
    "Тут сразу не скажешь, стало лучше или нет."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554e8127-c955-49ec-999b-e5837dcf3f59",
   "metadata": {},
   "source": [
    "## Узнаем, что будет на большем количестве эпох"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3da0a689-f230-44c0-8482-d7512a8ee2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 30\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(784, 512),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.BatchNorm1d(512),\n",
    "    torch.nn.Linear(512, 256),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.BatchNorm1d(256),\n",
    "    torch.nn.Linear(256, 128),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.BatchNorm1d(128),\n",
    "    torch.nn.Linear(128, 10)\n",
    ")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d39c5683-3b92-4c86-b6b8-35ff43768218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep: 0, taked: 2.932, train_loss: 0.473, train_acc: 0.825, test_loss: 0.454, test_acc: 0.825\n",
      "ep: 1, taked: 2.858, train_loss: 0.370, train_acc: 0.864, test_loss: 0.415, test_acc: 0.852\n",
      "ep: 2, taked: 2.859, train_loss: 0.337, train_acc: 0.875, test_loss: 0.406, test_acc: 0.856\n",
      "ep: 3, taked: 2.850, train_loss: 0.323, train_acc: 0.882, test_loss: 0.415, test_acc: 0.849\n",
      "ep: 4, taked: 2.856, train_loss: 0.298, train_acc: 0.890, test_loss: 0.382, test_acc: 0.865\n",
      "ep: 5, taked: 2.856, train_loss: 0.283, train_acc: 0.895, test_loss: 0.373, test_acc: 0.864\n",
      "ep: 6, taked: 2.874, train_loss: 0.272, train_acc: 0.899, test_loss: 0.407, test_acc: 0.859\n",
      "ep: 7, taked: 2.958, train_loss: 0.261, train_acc: 0.902, test_loss: 0.374, test_acc: 0.872\n",
      "ep: 8, taked: 2.928, train_loss: 0.251, train_acc: 0.905, test_loss: 0.403, test_acc: 0.866\n",
      "ep: 9, taked: 2.873, train_loss: 0.240, train_acc: 0.910, test_loss: 0.415, test_acc: 0.864\n",
      "ep: 10, taked: 2.850, train_loss: 0.230, train_acc: 0.914, test_loss: 0.377, test_acc: 0.877\n",
      "ep: 11, taked: 2.938, train_loss: 0.224, train_acc: 0.916, test_loss: 0.417, test_acc: 0.870\n",
      "ep: 12, taked: 2.917, train_loss: 0.213, train_acc: 0.920, test_loss: 0.427, test_acc: 0.873\n",
      "ep: 13, taked: 2.955, train_loss: 0.211, train_acc: 0.921, test_loss: 0.432, test_acc: 0.866\n",
      "ep: 14, taked: 2.926, train_loss: 0.204, train_acc: 0.923, test_loss: 0.501, test_acc: 0.867\n",
      "ep: 15, taked: 2.911, train_loss: 0.191, train_acc: 0.927, test_loss: 0.651, test_acc: 0.879\n",
      "ep: 16, taked: 2.957, train_loss: 0.185, train_acc: 0.930, test_loss: 0.527, test_acc: 0.869\n",
      "ep: 17, taked: 2.940, train_loss: 0.177, train_acc: 0.933, test_loss: 0.445, test_acc: 0.883\n",
      "ep: 18, taked: 2.874, train_loss: 0.172, train_acc: 0.935, test_loss: 1.142, test_acc: 0.881\n",
      "ep: 19, taked: 2.855, train_loss: 0.163, train_acc: 0.938, test_loss: 0.696, test_acc: 0.876\n",
      "ep: 20, taked: 2.854, train_loss: 0.161, train_acc: 0.940, test_loss: 1.353, test_acc: 0.880\n",
      "ep: 21, taked: 2.850, train_loss: 0.154, train_acc: 0.942, test_loss: 0.981, test_acc: 0.877\n",
      "ep: 22, taked: 2.864, train_loss: 0.148, train_acc: 0.943, test_loss: 1.375, test_acc: 0.877\n",
      "ep: 23, taked: 3.265, train_loss: 0.143, train_acc: 0.945, test_loss: 1.139, test_acc: 0.882\n",
      "ep: 24, taked: 2.856, train_loss: 0.140, train_acc: 0.947, test_loss: 0.925, test_acc: 0.878\n",
      "ep: 25, taked: 2.857, train_loss: 0.137, train_acc: 0.947, test_loss: 1.223, test_acc: 0.879\n",
      "ep: 26, taked: 2.969, train_loss: 0.127, train_acc: 0.951, test_loss: 1.302, test_acc: 0.879\n",
      "ep: 27, taked: 2.889, train_loss: 0.121, train_acc: 0.953, test_loss: 1.231, test_acc: 0.878\n",
      "ep: 28, taked: 2.902, train_loss: 0.115, train_acc: 0.955, test_loss: 1.381, test_acc: 0.880\n",
      "ep: 29, taked: 2.909, train_loss: 0.113, train_acc: 0.957, test_loss: 1.369, test_acc: 0.875\n"
     ]
    }
   ],
   "source": [
    "trainer = torch.optim.Adam(model.parameters(), lr=.01)\n",
    "train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74ef307-6501-47ab-bf23-97d852aedf7d",
   "metadata": {},
   "source": [
    "По итогам 30 эпох видно, что усложнение сети с batch norm повысило качество обучения."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b3a4d9-dca8-4ba7-99be-478ef7f1da27",
   "metadata": {},
   "source": [
    "## Попробуем drop out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b92a1d67-eda9-41ee-b1bf-cc228e2379c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(784, 2560),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Dropout(0.5),\n",
    "    torch.nn.Linear(2560, 1280),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Dropout(0.5),\n",
    "    torch.nn.Linear(1280, 640),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Dropout(0.5),\n",
    "    torch.nn.Linear(640, 10)\n",
    ")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d6ea0eef-76b7-45b4-b26f-b6e281337362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep: 0, taked: 6.836, train_loss: 1.180, train_acc: 0.632, test_loss: 0.658, test_acc: 0.765\n",
      "ep: 1, taked: 6.892, train_loss: 0.883, train_acc: 0.673, test_loss: 0.650, test_acc: 0.765\n",
      "ep: 2, taked: 6.814, train_loss: 0.934, train_acc: 0.658, test_loss: 0.743, test_acc: 0.771\n",
      "ep: 3, taked: 6.837, train_loss: 0.953, train_acc: 0.655, test_loss: 0.656, test_acc: 0.769\n",
      "ep: 4, taked: 6.750, train_loss: 0.961, train_acc: 0.645, test_loss: 0.670, test_acc: 0.770\n",
      "ep: 5, taked: 6.794, train_loss: 1.002, train_acc: 0.624, test_loss: 0.641, test_acc: 0.770\n",
      "ep: 6, taked: 7.243, train_loss: 1.014, train_acc: 0.613, test_loss: 0.703, test_acc: 0.704\n",
      "ep: 7, taked: 7.131, train_loss: 1.064, train_acc: 0.602, test_loss: 0.740, test_acc: 0.736\n",
      "ep: 8, taked: 7.343, train_loss: 1.039, train_acc: 0.612, test_loss: 0.715, test_acc: 0.703\n",
      "ep: 9, taked: 7.031, train_loss: 1.046, train_acc: 0.597, test_loss: 0.736, test_acc: 0.684\n",
      "ep: 10, taked: 6.931, train_loss: 1.095, train_acc: 0.581, test_loss: 0.708, test_acc: 0.708\n",
      "ep: 11, taked: 6.887, train_loss: 1.043, train_acc: 0.598, test_loss: 0.681, test_acc: 0.750\n",
      "ep: 12, taked: 7.120, train_loss: 1.091, train_acc: 0.592, test_loss: 0.809, test_acc: 0.727\n",
      "ep: 13, taked: 7.570, train_loss: 1.119, train_acc: 0.584, test_loss: 0.835, test_acc: 0.685\n",
      "ep: 14, taked: 7.070, train_loss: 1.135, train_acc: 0.571, test_loss: 0.803, test_acc: 0.696\n",
      "ep: 15, taked: 6.993, train_loss: 1.097, train_acc: 0.583, test_loss: 0.778, test_acc: 0.694\n",
      "ep: 16, taked: 7.058, train_loss: 1.039, train_acc: 0.589, test_loss: 0.750, test_acc: 0.699\n",
      "ep: 17, taked: 7.622, train_loss: 1.068, train_acc: 0.581, test_loss: 0.800, test_acc: 0.661\n",
      "ep: 18, taked: 7.052, train_loss: 1.091, train_acc: 0.573, test_loss: 0.843, test_acc: 0.651\n",
      "ep: 19, taked: 7.281, train_loss: 1.096, train_acc: 0.570, test_loss: 0.795, test_acc: 0.661\n",
      "ep: 20, taked: 7.088, train_loss: 1.110, train_acc: 0.563, test_loss: 0.806, test_acc: 0.677\n",
      "ep: 21, taked: 7.086, train_loss: 1.102, train_acc: 0.568, test_loss: 0.818, test_acc: 0.699\n",
      "ep: 22, taked: 7.652, train_loss: 1.106, train_acc: 0.578, test_loss: 0.761, test_acc: 0.678\n",
      "ep: 23, taked: 7.093, train_loss: 1.091, train_acc: 0.588, test_loss: 0.784, test_acc: 0.703\n",
      "ep: 24, taked: 7.122, train_loss: 1.134, train_acc: 0.577, test_loss: 0.797, test_acc: 0.700\n",
      "ep: 25, taked: 6.966, train_loss: 1.145, train_acc: 0.560, test_loss: 0.790, test_acc: 0.704\n",
      "ep: 26, taked: 7.621, train_loss: 1.121, train_acc: 0.569, test_loss: 0.867, test_acc: 0.696\n",
      "ep: 27, taked: 7.154, train_loss: 1.123, train_acc: 0.565, test_loss: 0.859, test_acc: 0.653\n",
      "ep: 28, taked: 7.145, train_loss: 1.192, train_acc: 0.532, test_loss: 0.849, test_acc: 0.634\n",
      "ep: 29, taked: 7.090, train_loss: 1.188, train_acc: 0.526, test_loss: 0.844, test_acc: 0.688\n"
     ]
    }
   ],
   "source": [
    "trainer = torch.optim.Adam(model.parameters(), lr=.01)\n",
    "train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e47a03-2514-40f2-bfb0-935e1f3fff51",
   "metadata": {},
   "source": [
    "Замена batch norm на drop out сильно снизила качество обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b2c308-52c4-4437-acad-8383e2bd4b16",
   "metadata": {},
   "source": [
    "В итоге лучший результат показал предыдущий вариант (усложненная сеть с batch norm).\n",
    "Прогоним его на 50 эпохах для закрепления результата."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "70e8a0ec-a369-46e6-b381-a7de3bbfad79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep: 0, taked: 3.101, train_loss: 0.471, train_acc: 0.825, test_loss: 0.440, test_acc: 0.838\n",
      "ep: 1, taked: 3.031, train_loss: 0.370, train_acc: 0.864, test_loss: 0.411, test_acc: 0.855\n",
      "ep: 2, taked: 3.031, train_loss: 0.337, train_acc: 0.876, test_loss: 0.414, test_acc: 0.851\n",
      "ep: 3, taked: 3.128, train_loss: 0.313, train_acc: 0.885, test_loss: 0.390, test_acc: 0.861\n",
      "ep: 4, taked: 3.041, train_loss: 0.300, train_acc: 0.889, test_loss: 0.361, test_acc: 0.874\n",
      "ep: 5, taked: 3.021, train_loss: 0.282, train_acc: 0.894, test_loss: 0.378, test_acc: 0.867\n",
      "ep: 6, taked: 3.060, train_loss: 0.273, train_acc: 0.898, test_loss: 0.361, test_acc: 0.871\n",
      "ep: 7, taked: 3.048, train_loss: 0.265, train_acc: 0.901, test_loss: 0.379, test_acc: 0.873\n",
      "ep: 8, taked: 3.050, train_loss: 0.248, train_acc: 0.907, test_loss: 0.356, test_acc: 0.875\n",
      "ep: 9, taked: 3.123, train_loss: 0.240, train_acc: 0.910, test_loss: 0.405, test_acc: 0.875\n",
      "ep: 10, taked: 3.148, train_loss: 0.230, train_acc: 0.914, test_loss: 0.397, test_acc: 0.876\n",
      "ep: 11, taked: 3.008, train_loss: 0.220, train_acc: 0.917, test_loss: 0.450, test_acc: 0.875\n",
      "ep: 12, taked: 3.021, train_loss: 0.214, train_acc: 0.919, test_loss: 0.458, test_acc: 0.863\n",
      "ep: 13, taked: 3.025, train_loss: 0.208, train_acc: 0.921, test_loss: 0.492, test_acc: 0.859\n",
      "ep: 14, taked: 3.015, train_loss: 0.197, train_acc: 0.925, test_loss: 0.457, test_acc: 0.873\n",
      "ep: 15, taked: 3.010, train_loss: 0.189, train_acc: 0.928, test_loss: 0.444, test_acc: 0.873\n",
      "ep: 16, taked: 3.011, train_loss: 0.180, train_acc: 0.933, test_loss: 0.505, test_acc: 0.869\n",
      "ep: 17, taked: 3.015, train_loss: 0.172, train_acc: 0.935, test_loss: 0.479, test_acc: 0.874\n",
      "ep: 18, taked: 3.106, train_loss: 0.165, train_acc: 0.937, test_loss: 0.534, test_acc: 0.868\n",
      "ep: 19, taked: 3.214, train_loss: 0.163, train_acc: 0.938, test_loss: 0.503, test_acc: 0.877\n",
      "ep: 20, taked: 3.302, train_loss: 0.156, train_acc: 0.941, test_loss: 0.505, test_acc: 0.878\n",
      "ep: 21, taked: 3.193, train_loss: 0.161, train_acc: 0.939, test_loss: 0.579, test_acc: 0.873\n",
      "ep: 22, taked: 2.986, train_loss: 0.155, train_acc: 0.941, test_loss: 0.551, test_acc: 0.864\n",
      "ep: 23, taked: 3.061, train_loss: 0.137, train_acc: 0.949, test_loss: 0.546, test_acc: 0.874\n",
      "ep: 24, taked: 3.014, train_loss: 0.132, train_acc: 0.950, test_loss: 0.558, test_acc: 0.878\n",
      "ep: 25, taked: 3.010, train_loss: 0.131, train_acc: 0.950, test_loss: 0.773, test_acc: 0.863\n",
      "ep: 26, taked: 3.128, train_loss: 0.126, train_acc: 0.952, test_loss: 0.653, test_acc: 0.870\n",
      "ep: 27, taked: 2.972, train_loss: 0.122, train_acc: 0.954, test_loss: 0.704, test_acc: 0.870\n",
      "ep: 28, taked: 2.969, train_loss: 0.118, train_acc: 0.955, test_loss: 0.692, test_acc: 0.862\n",
      "ep: 29, taked: 2.986, train_loss: 0.116, train_acc: 0.957, test_loss: 0.632, test_acc: 0.864\n",
      "ep: 30, taked: 3.046, train_loss: 0.115, train_acc: 0.955, test_loss: 0.682, test_acc: 0.865\n",
      "ep: 31, taked: 2.965, train_loss: 0.110, train_acc: 0.958, test_loss: 0.581, test_acc: 0.880\n",
      "ep: 32, taked: 2.980, train_loss: 0.109, train_acc: 0.958, test_loss: 0.597, test_acc: 0.881\n",
      "ep: 33, taked: 2.999, train_loss: 0.103, train_acc: 0.960, test_loss: 0.702, test_acc: 0.868\n",
      "ep: 34, taked: 2.981, train_loss: 0.095, train_acc: 0.964, test_loss: 0.748, test_acc: 0.872\n",
      "ep: 35, taked: 2.970, train_loss: 0.094, train_acc: 0.964, test_loss: 0.736, test_acc: 0.878\n",
      "ep: 36, taked: 2.965, train_loss: 0.094, train_acc: 0.964, test_loss: 0.698, test_acc: 0.871\n",
      "ep: 37, taked: 2.981, train_loss: 0.096, train_acc: 0.964, test_loss: 0.635, test_acc: 0.876\n",
      "ep: 38, taked: 2.980, train_loss: 0.093, train_acc: 0.965, test_loss: 0.719, test_acc: 0.869\n",
      "ep: 39, taked: 2.978, train_loss: 0.088, train_acc: 0.967, test_loss: 0.704, test_acc: 0.871\n",
      "ep: 40, taked: 2.967, train_loss: 0.081, train_acc: 0.969, test_loss: 0.853, test_acc: 0.866\n",
      "ep: 41, taked: 3.226, train_loss: 0.081, train_acc: 0.969, test_loss: 0.784, test_acc: 0.873\n",
      "ep: 42, taked: 2.992, train_loss: 0.078, train_acc: 0.970, test_loss: 0.734, test_acc: 0.877\n",
      "ep: 43, taked: 2.986, train_loss: 0.071, train_acc: 0.973, test_loss: 0.809, test_acc: 0.878\n",
      "ep: 44, taked: 2.988, train_loss: 0.085, train_acc: 0.968, test_loss: 0.735, test_acc: 0.875\n",
      "ep: 45, taked: 2.964, train_loss: 0.072, train_acc: 0.972, test_loss: 0.854, test_acc: 0.879\n",
      "ep: 46, taked: 3.007, train_loss: 0.066, train_acc: 0.974, test_loss: 0.876, test_acc: 0.876\n",
      "ep: 47, taked: 2.973, train_loss: 0.069, train_acc: 0.974, test_loss: 0.891, test_acc: 0.876\n",
      "ep: 48, taked: 2.985, train_loss: 0.065, train_acc: 0.975, test_loss: 0.880, test_acc: 0.877\n",
      "ep: 49, taked: 2.982, train_loss: 0.064, train_acc: 0.975, test_loss: 0.845, test_acc: 0.879\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(784, 512),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.BatchNorm1d(512),\n",
    "    torch.nn.Linear(512, 256),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.BatchNorm1d(256),\n",
    "    torch.nn.Linear(256, 128),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.BatchNorm1d(128),\n",
    "    torch.nn.Linear(128, 10)\n",
    ")\n",
    "model = model.to(device)\n",
    "trainer = torch.optim.Adam(model.parameters(), lr=.01)\n",
    "train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bee67a-9b45-4bb7-8435-8d13b4f029b8",
   "metadata": {},
   "source": [
    "Качество до сих пор не доходит дотребуемого"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a524cee-873d-4793-b9c8-887f58b9502c",
   "metadata": {},
   "source": [
    "## Попробуем L2-регуляризацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0461d2e9-c853-497d-bc79-af1faf2d3ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep: 0, taked: 3.079, train_loss: 0.483, train_acc: 0.821, test_loss: 0.515, test_acc: 0.841\n",
      "ep: 1, taked: 3.074, train_loss: 0.374, train_acc: 0.862, test_loss: 0.413, test_acc: 0.850\n",
      "ep: 2, taked: 3.054, train_loss: 0.343, train_acc: 0.874, test_loss: 0.427, test_acc: 0.844\n",
      "ep: 3, taked: 3.127, train_loss: 0.321, train_acc: 0.881, test_loss: 0.429, test_acc: 0.843\n",
      "ep: 4, taked: 3.052, train_loss: 0.311, train_acc: 0.884, test_loss: 0.412, test_acc: 0.853\n",
      "ep: 5, taked: 3.060, train_loss: 0.297, train_acc: 0.890, test_loss: 0.420, test_acc: 0.846\n",
      "ep: 6, taked: 3.097, train_loss: 0.285, train_acc: 0.894, test_loss: 0.382, test_acc: 0.866\n",
      "ep: 7, taked: 3.043, train_loss: 0.276, train_acc: 0.898, test_loss: 0.361, test_acc: 0.874\n",
      "ep: 8, taked: 3.053, train_loss: 0.268, train_acc: 0.900, test_loss: 0.398, test_acc: 0.860\n",
      "ep: 9, taked: 3.221, train_loss: 0.266, train_acc: 0.900, test_loss: 0.412, test_acc: 0.854\n",
      "ep: 10, taked: 3.168, train_loss: 0.257, train_acc: 0.903, test_loss: 0.431, test_acc: 0.854\n",
      "ep: 11, taked: 3.046, train_loss: 0.251, train_acc: 0.906, test_loss: 0.402, test_acc: 0.856\n",
      "ep: 12, taked: 3.060, train_loss: 0.242, train_acc: 0.910, test_loss: 0.377, test_acc: 0.867\n",
      "ep: 13, taked: 3.048, train_loss: 0.240, train_acc: 0.909, test_loss: 0.412, test_acc: 0.854\n",
      "ep: 14, taked: 3.049, train_loss: 0.235, train_acc: 0.912, test_loss: 0.402, test_acc: 0.865\n",
      "ep: 15, taked: 3.060, train_loss: 0.223, train_acc: 0.916, test_loss: 0.449, test_acc: 0.851\n",
      "ep: 16, taked: 3.052, train_loss: 0.227, train_acc: 0.914, test_loss: 0.442, test_acc: 0.847\n",
      "ep: 17, taked: 3.092, train_loss: 0.221, train_acc: 0.918, test_loss: 0.414, test_acc: 0.866\n",
      "ep: 18, taked: 3.049, train_loss: 0.214, train_acc: 0.920, test_loss: 0.407, test_acc: 0.870\n",
      "ep: 19, taked: 3.104, train_loss: 0.215, train_acc: 0.920, test_loss: 0.458, test_acc: 0.859\n",
      "ep: 20, taked: 3.341, train_loss: 0.209, train_acc: 0.921, test_loss: 0.436, test_acc: 0.857\n",
      "ep: 21, taked: 3.057, train_loss: 0.205, train_acc: 0.923, test_loss: 0.410, test_acc: 0.864\n",
      "ep: 22, taked: 3.055, train_loss: 0.200, train_acc: 0.924, test_loss: 0.499, test_acc: 0.849\n",
      "ep: 23, taked: 3.062, train_loss: 0.196, train_acc: 0.925, test_loss: 0.506, test_acc: 0.840\n",
      "ep: 24, taked: 3.050, train_loss: 0.196, train_acc: 0.926, test_loss: 0.439, test_acc: 0.863\n",
      "ep: 25, taked: 3.075, train_loss: 0.185, train_acc: 0.930, test_loss: 0.445, test_acc: 0.869\n",
      "ep: 26, taked: 3.056, train_loss: 0.190, train_acc: 0.928, test_loss: 0.416, test_acc: 0.870\n",
      "ep: 27, taked: 3.057, train_loss: 0.181, train_acc: 0.931, test_loss: 0.468, test_acc: 0.860\n",
      "ep: 28, taked: 3.104, train_loss: 0.182, train_acc: 0.930, test_loss: 0.442, test_acc: 0.871\n",
      "ep: 29, taked: 3.082, train_loss: 0.182, train_acc: 0.931, test_loss: 0.431, test_acc: 0.862\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(784, 512),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.BatchNorm1d(512),\n",
    "    torch.nn.Linear(512, 256),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.BatchNorm1d(256),\n",
    "    torch.nn.Linear(256, 128),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.BatchNorm1d(128),\n",
    "    torch.nn.Linear(128, 10)\n",
    ")\n",
    "model = model.to(device)\n",
    "trainer = torch.optim.Adam(model.parameters(), lr=.01, weight_decay=1e-5)\n",
    "train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d865f881-b2b8-4efb-a70a-bde143dec5e9",
   "metadata": {},
   "source": [
    "L2-регуляризация желаемого эффекта не дала.\n",
    "В итоге самым качественным варинтом была усложненная сеть с batch norm (без drop out и l2-reg).\n",
    "По-скольку по итогам 50 эпох качество незначительно упало с 88% (87,9%), стоит остановить обучение чуть раньше.\n",
    "Попробуем это сделать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19a73745-3896-432f-8167-ec9812d8f9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_acc = 0.88\n",
    "\n",
    "def train_model():\n",
    "    for ep in range(num_epochs):\n",
    "        train_iters, train_passed  = 0, 0\n",
    "        train_loss, train_acc = 0., 0.\n",
    "        start=time.time()\n",
    "        \n",
    "        model.train()\n",
    "        for X, y in train:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            trainer.zero_grad()\n",
    "            y_pred = model(X)\n",
    "            l = loss(y_pred, y)\n",
    "            l.backward()\n",
    "            trainer.step()\n",
    "            train_loss += l.item()\n",
    "            train_acc += (y_pred.argmax(dim=1) == y).sum().item()\n",
    "            train_iters += 1\n",
    "            train_passed += len(X)\n",
    "        \n",
    "        test_iters, test_passed  = 0, 0\n",
    "        test_loss, test_acc = 0., 0.\n",
    "        model.eval()\n",
    "        for X, y in test:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            y_pred = model(X)\n",
    "            l = loss(y_pred, y)\n",
    "            test_loss += l.item()\n",
    "            test_acc += (y_pred.argmax(dim=1) == y).sum().item()\n",
    "            test_iters += 1\n",
    "            test_passed += len(X)\n",
    "            \n",
    "        print(\"ep: {}, taked: {:.3f}, train_loss: {:.3f}, train_acc: {:.3f}, test_loss: {:.3f}, test_acc: {:.3f}\".format(\n",
    "            ep, time.time() - start, train_loss / train_iters, train_acc / train_passed,\n",
    "            test_loss / test_iters, test_acc / test_passed)\n",
    "        )\n",
    "        if (test_acc / test_passed) >= result_acc:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "921a10ee-3d1f-43bd-8600-527216e81aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep: 0, taked: 2.901, train_loss: 0.479, train_acc: 0.822, test_loss: 0.423, test_acc: 0.850\n",
      "ep: 1, taked: 2.895, train_loss: 0.373, train_acc: 0.864, test_loss: 0.431, test_acc: 0.849\n",
      "ep: 2, taked: 2.844, train_loss: 0.342, train_acc: 0.874, test_loss: 0.415, test_acc: 0.850\n",
      "ep: 3, taked: 2.883, train_loss: 0.313, train_acc: 0.885, test_loss: 0.389, test_acc: 0.858\n",
      "ep: 4, taked: 2.847, train_loss: 0.296, train_acc: 0.891, test_loss: 0.385, test_acc: 0.859\n",
      "ep: 5, taked: 2.827, train_loss: 0.286, train_acc: 0.894, test_loss: 0.369, test_acc: 0.867\n",
      "ep: 6, taked: 2.828, train_loss: 0.269, train_acc: 0.900, test_loss: 0.369, test_acc: 0.873\n",
      "ep: 7, taked: 2.841, train_loss: 0.260, train_acc: 0.903, test_loss: 0.387, test_acc: 0.865\n",
      "ep: 8, taked: 2.868, train_loss: 0.249, train_acc: 0.908, test_loss: 0.379, test_acc: 0.871\n",
      "ep: 9, taked: 2.844, train_loss: 0.237, train_acc: 0.911, test_loss: 0.381, test_acc: 0.869\n",
      "ep: 10, taked: 2.843, train_loss: 0.232, train_acc: 0.913, test_loss: 0.408, test_acc: 0.866\n",
      "ep: 11, taked: 2.835, train_loss: 0.226, train_acc: 0.916, test_loss: 0.386, test_acc: 0.871\n",
      "ep: 12, taked: 2.834, train_loss: 0.215, train_acc: 0.918, test_loss: 0.413, test_acc: 0.865\n",
      "ep: 13, taked: 2.830, train_loss: 0.206, train_acc: 0.922, test_loss: 0.426, test_acc: 0.862\n",
      "ep: 14, taked: 2.836, train_loss: 0.196, train_acc: 0.926, test_loss: 0.391, test_acc: 0.862\n",
      "ep: 15, taked: 2.864, train_loss: 0.192, train_acc: 0.927, test_loss: 0.399, test_acc: 0.864\n",
      "ep: 16, taked: 2.830, train_loss: 0.182, train_acc: 0.931, test_loss: 0.391, test_acc: 0.873\n",
      "ep: 17, taked: 2.832, train_loss: 0.179, train_acc: 0.932, test_loss: 0.412, test_acc: 0.874\n",
      "ep: 18, taked: 2.847, train_loss: 0.172, train_acc: 0.936, test_loss: 0.395, test_acc: 0.876\n",
      "ep: 19, taked: 3.171, train_loss: 0.162, train_acc: 0.939, test_loss: 0.425, test_acc: 0.872\n",
      "ep: 20, taked: 2.837, train_loss: 0.160, train_acc: 0.940, test_loss: 0.470, test_acc: 0.862\n",
      "ep: 21, taked: 2.849, train_loss: 0.153, train_acc: 0.941, test_loss: 0.479, test_acc: 0.867\n",
      "ep: 22, taked: 2.828, train_loss: 0.144, train_acc: 0.946, test_loss: 0.455, test_acc: 0.873\n",
      "ep: 23, taked: 2.769, train_loss: 0.140, train_acc: 0.946, test_loss: 0.474, test_acc: 0.870\n",
      "ep: 24, taked: 2.875, train_loss: 0.140, train_acc: 0.946, test_loss: 0.455, test_acc: 0.869\n",
      "ep: 25, taked: 2.846, train_loss: 0.137, train_acc: 0.949, test_loss: 0.456, test_acc: 0.867\n",
      "ep: 26, taked: 2.861, train_loss: 0.124, train_acc: 0.953, test_loss: 0.488, test_acc: 0.872\n",
      "ep: 27, taked: 2.875, train_loss: 0.124, train_acc: 0.952, test_loss: 0.618, test_acc: 0.858\n",
      "ep: 28, taked: 2.846, train_loss: 0.120, train_acc: 0.954, test_loss: 0.520, test_acc: 0.867\n",
      "ep: 29, taked: 2.881, train_loss: 0.116, train_acc: 0.955, test_loss: 0.563, test_acc: 0.869\n",
      "ep: 30, taked: 3.135, train_loss: 0.114, train_acc: 0.957, test_loss: 0.490, test_acc: 0.874\n",
      "ep: 31, taked: 2.884, train_loss: 0.112, train_acc: 0.957, test_loss: 0.549, test_acc: 0.873\n",
      "ep: 32, taked: 2.870, train_loss: 0.104, train_acc: 0.960, test_loss: 0.561, test_acc: 0.875\n",
      "ep: 33, taked: 2.837, train_loss: 0.102, train_acc: 0.960, test_loss: 0.547, test_acc: 0.880\n",
      "ep: 34, taked: 2.834, train_loss: 0.097, train_acc: 0.963, test_loss: 0.586, test_acc: 0.870\n",
      "ep: 35, taked: 2.827, train_loss: 0.098, train_acc: 0.963, test_loss: 0.577, test_acc: 0.873\n",
      "ep: 36, taked: 2.838, train_loss: 0.095, train_acc: 0.963, test_loss: 0.573, test_acc: 0.882\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(784, 512),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.BatchNorm1d(512),\n",
    "    torch.nn.Linear(512, 256),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.BatchNorm1d(256),\n",
    "    torch.nn.Linear(256, 128),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.BatchNorm1d(128),\n",
    "    torch.nn.Linear(128, 10)\n",
    ")\n",
    "model = model.to(device)\n",
    "trainer = torch.optim.Adam(model.parameters(), lr=.01)\n",
    "train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b71b0e3-3cd4-422a-be89-c8b4c1ae4214",
   "metadata": {},
   "source": [
    "Сработало! Не уверен, что это true-way, но тем не менее :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b88eae7-3e3a-49a3-8ad3-19d7ee68cea8",
   "metadata": {},
   "source": [
    "## Попробуем сверточную сеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5376f77-1d40-48aa-9625-cf3719bd67db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mps'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21cfe25f-58ec-411b-b080-fd2f015f51a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision as tv\n",
    "from torch import nn\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e719beea-40eb-43e1-a93c-e024f8b40d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "\n",
    "transforms = tv.transforms.Compose([\n",
    "    # tv.transforms.Resize(32),\n",
    "    tv.transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_dataset = tv.datasets.FashionMNIST('.', train=True, transform=transforms, download=True)\n",
    "test_dataset = tv.datasets.FashionMNIST('.', train=False, transform=transforms, download=True)\n",
    "train_iter = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "test_iter = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7dd39581-daab-4e7d-b18f-a9c0408af438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_dataset[0][0].numpy().reshape(32,32), cmap='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4ad534b8-ea6c-4b1b-ab0f-950d78c286e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=replicate)\n",
       "  (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (2): ReLU()\n",
       "  (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=replicate)\n",
       "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (5): ReLU()\n",
       "  (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=replicate)\n",
       "  (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (8): ReLU()\n",
       "  (9): Flatten(start_dim=1, end_dim=-1)\n",
       "  (10): Dropout(p=0.2, inplace=False)\n",
       "  (11): Linear(in_features=1152, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = nn.Sequential(\n",
    "#     nn.Conv2d(1, 6, kernel_size=4, padding=0),\n",
    "#     nn.Tanh(),\n",
    "#     nn.AvgPool2d(2, stride=2),\n",
    "#     nn.Conv2d(6, 16, kernel_size=4),\n",
    "#     nn.Tanh(),\n",
    "#     nn.AvgPool2d(2, stride=2),\n",
    "#     nn.Conv2d(16, 120, kernel_size=4),\n",
    "#     nn.Flatten(),\n",
    "#     torch.nn.Dropout(0.2),\n",
    "#     nn.Linear(120, 84),\n",
    "#     nn.Tanh(),\n",
    "#     nn.Linear(84, 10)\n",
    "# )\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(1, 32, kernel_size = 3, padding = 1, padding_mode = 'replicate'),\n",
    "    torch.nn.MaxPool2d(kernel_size=2),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Conv2d(32, 64, kernel_size = 3, padding = 1, padding_mode = 'replicate'),\n",
    "    torch.nn.MaxPool2d(kernel_size=2),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Conv2d(64, 128, kernel_size = 3, padding = 1, padding_mode = 'replicate'),\n",
    "    torch.nn.MaxPool2d(kernel_size=2),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Dropout(0.2),\n",
    "    torch.nn.Linear(1152, 10)\n",
    "    )\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef7bd324-7c2e-465e-99d3-824fcd5c0a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, train_iter, test_iter, optimizer, num_epochs, device):\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()\n",
    "    \n",
    "        for X, y in train_iter:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y)\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            train_l_sum += l.item()\n",
    "            train_acc_sum += (y_hat.argmax(axis=1) == y).sum().item()\n",
    "            n += y.shape[0]\n",
    "    \n",
    "        test_acc = evaluate_accuracy(test_iter, net, device)\n",
    "        print(f'epoch {epoch + 1}, loss {train_l_sum / n:.4f}, train acc {train_acc_sum / n:.3f}' \\\n",
    "              f', test acc {test_acc:.3f}, time {time.time() - start:.1f} sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2df974cd-9f84-4bd3-90a0-efb04bf3853b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iter, net, device):\n",
    "    acc_sum, n = torch.Tensor([0]).to(device), 0\n",
    "    for X, y in data_iter:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        acc_sum += (net(X).argmax(axis=1) == y).sum()\n",
    "        n += y.shape[0]\n",
    "    return acc_sum.item() / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20be407a-2df1-4acb-bdeb-34971e228d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.0028, train acc 0.750, test acc 0.822, time 6.1 sec\n",
      "epoch 2, loss 0.0016, train acc 0.854, test acc 0.854, time 5.6 sec\n",
      "epoch 3, loss 0.0014, train acc 0.875, test acc 0.865, time 5.7 sec\n",
      "epoch 4, loss 0.0012, train acc 0.887, test acc 0.873, time 5.6 sec\n",
      "epoch 5, loss 0.0011, train acc 0.894, test acc 0.878, time 5.8 sec\n",
      "epoch 6, loss 0.0011, train acc 0.900, test acc 0.886, time 5.5 sec\n",
      "epoch 7, loss 0.0010, train acc 0.906, test acc 0.892, time 5.4 sec\n",
      "epoch 8, loss 0.0010, train acc 0.911, test acc 0.896, time 5.8 sec\n",
      "epoch 9, loss 0.0009, train acc 0.914, test acc 0.897, time 5.7 sec\n",
      "epoch 10, loss 0.0009, train acc 0.918, test acc 0.898, time 5.8 sec\n",
      "epoch 11, loss 0.0009, train acc 0.921, test acc 0.899, time 5.6 sec\n",
      "epoch 12, loss 0.0008, train acc 0.924, test acc 0.898, time 5.4 sec\n",
      "epoch 13, loss 0.0008, train acc 0.925, test acc 0.903, time 6.1 sec\n",
      "epoch 14, loss 0.0008, train acc 0.929, test acc 0.898, time 5.5 sec\n",
      "epoch 15, loss 0.0007, train acc 0.930, test acc 0.904, time 5.5 sec\n",
      "epoch 16, loss 0.0007, train acc 0.933, test acc 0.904, time 5.6 sec\n",
      "epoch 17, loss 0.0007, train acc 0.935, test acc 0.905, time 5.4 sec\n",
      "epoch 18, loss 0.0007, train acc 0.937, test acc 0.910, time 5.4 sec\n",
      "epoch 19, loss 0.0006, train acc 0.939, test acc 0.908, time 5.9 sec\n",
      "epoch 20, loss 0.0006, train acc 0.940, test acc 0.903, time 5.5 sec\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "trainer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "train(model, train_iter, test_iter, trainer, num_epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b890dd-3791-4a58-bb4b-3589d3d3dfb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
