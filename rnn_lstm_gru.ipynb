{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7e4af781-7846-48a3-b232-e78e972952ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import time\n",
    "from torch import nn\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c68fad9-415d-4fd4-8ada-a4451b8c1b2b",
   "metadata": {},
   "source": [
    "### Функция генерации новой последовательности из исходной"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "85add6e2-8e03-4b0f-8cb6-52487ef18662",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_y_sequence(x: List[int]) -> List[int]:\n",
    "    y = [0 for _ in x]\n",
    "    y[0] = x[0]\n",
    "    for i in range(1, len(x)):\n",
    "        y[i] = x[i] + x[0]\n",
    "        if y[i] >= 10:\n",
    "            y[i] -= 10\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a7ba1bfa-989d-4d05-a2d2-5e6200403331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 7, 1, 2]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [5, 2, 6, 7]\n",
    "y = get_y_sequence(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c420d15d-c32c-4335-a8ab-ca7e0668b7fa",
   "metadata": {},
   "source": [
    "### Создание датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "9661399f-a8e8-4d6e-9f05-c9ca6ebec113",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQUENCE_LEN = 15\n",
    "DATASET_LEN = 10000\n",
    "X = [[random.randint(0, 9) for i in range(SEQUENCE_LEN)] for _ in range(DATASET_LEN)]\n",
    "Y = [get_y_sequence(x) for x in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d832a02a-321a-4c59-829f-18e8204c4736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[7, 6, 9, 5, 4, 3, 8, 9, 2, 2, 0, 0, 8, 1, 4],\n",
       " [0, 4, 4, 8, 8, 3, 2, 5, 2, 9, 4, 1, 6, 1, 8]]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "06487c68-c81b-400d-83f1-6718ef78200d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[7, 3, 6, 2, 1, 0, 5, 6, 9, 9, 7, 7, 5, 8, 1],\n",
       " [0, 4, 4, 8, 8, 3, 2, 5, 2, 9, 4, 1, 6, 1, 8]]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459088fc-1b7f-40df-8393-af51a6eb45b8",
   "metadata": {},
   "source": [
    "По-скольку значения уже типа int, дополнительных преобразований не требуется, можно сразу переводить в тензоры."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "61333b94-7681-494c-8172-2b9e4976b11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(X)\n",
    "Y_train = torch.tensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "9d95ce37-b917-4e38-8856-6dddbbb8b228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7, 6, 9, 5, 4, 3, 8, 9, 2, 2, 0, 0, 8, 1, 4],\n",
       "        [0, 4, 4, 8, 8, 3, 2, 5, 2, 9, 4, 1, 6, 1, 8]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "ffc5a8a2-bad4-40d5-abc9-c1326a7edadd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7, 3, 6, 2, 1, 0, 5, 6, 9, 9, 7, 7, 5, 8, 1],\n",
       "        [0, 4, 4, 8, 8, 3, 2, 5, 2, 9, 4, 1, 6, 1, 8]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2584e3-9f13-4087-ad48-e10d98522e9a",
   "metadata": {},
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "9182db71-b66d-49af-bf76-98a0a7ded1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(10, 30)\n",
    "        self.rnn = torch.nn.RNN(30, 128, batch_first=True)\n",
    "        self.out = torch.nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, sentences, state=None):\n",
    "        x = self.embedding(sentences)\n",
    "        x, s = self.rnn(x) # берём выход с последнего слоя для всех токенов, а не скрытое состояние\n",
    "        return self.out(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "3220a0a0-a218-4b1e-8586-f19a92540166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (embedding): Embedding(10, 30)\n",
       "  (rnn): RNN(30, 128, batch_first=True)\n",
       "  (out): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Network()\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "b543db1b-e7a9-4f05-95be-a63760c59319",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()  # типичный лосс многоклассовой классификации\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "fc7e5c49-be2b-4956-a193-62e9fe0d0b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. Time: 0.888, Train loss: 2.283\n",
      "Epoch 1. Time: 0.789, Train loss: 2.282\n",
      "Epoch 2. Time: 0.895, Train loss: 2.280\n",
      "Epoch 3. Time: 0.808, Train loss: 2.278\n",
      "Epoch 4. Time: 0.775, Train loss: 2.275\n",
      "Epoch 5. Time: 0.774, Train loss: 2.270\n",
      "Epoch 6. Time: 0.775, Train loss: 2.263\n",
      "Epoch 7. Time: 0.777, Train loss: 2.253\n",
      "Epoch 8. Time: 0.784, Train loss: 2.241\n",
      "Epoch 9. Time: 0.778, Train loss: 2.220\n",
      "Epoch 10. Time: 0.778, Train loss: 2.193\n",
      "Epoch 11. Time: 0.775, Train loss: 2.167\n",
      "Epoch 12. Time: 0.764, Train loss: 2.137\n",
      "Epoch 13. Time: 0.819, Train loss: 2.107\n",
      "Epoch 14. Time: 0.771, Train loss: 2.076\n",
      "Epoch 15. Time: 0.768, Train loss: 2.045\n",
      "Epoch 16. Time: 0.781, Train loss: 2.017\n",
      "Epoch 17. Time: 0.769, Train loss: 1.994\n",
      "Epoch 18. Time: 0.816, Train loss: 1.974\n",
      "Epoch 19. Time: 0.805, Train loss: 1.958\n",
      "Epoch 20. Time: 0.773, Train loss: 1.945\n",
      "Epoch 21. Time: 0.775, Train loss: 1.933\n",
      "Epoch 22. Time: 0.789, Train loss: 1.923\n",
      "Epoch 23. Time: 0.786, Train loss: 1.915\n",
      "Epoch 24. Time: 0.779, Train loss: 1.907\n",
      "Epoch 25. Time: 0.769, Train loss: 1.899\n",
      "Epoch 26. Time: 0.781, Train loss: 1.893\n",
      "Epoch 27. Time: 0.793, Train loss: 1.887\n",
      "Epoch 28. Time: 0.787, Train loss: 1.881\n",
      "Epoch 29. Time: 0.788, Train loss: 1.876\n",
      "Epoch 30. Time: 0.800, Train loss: 1.871\n",
      "Epoch 31. Time: 0.769, Train loss: 1.866\n",
      "Epoch 32. Time: 0.768, Train loss: 1.861\n",
      "Epoch 33. Time: 0.782, Train loss: 1.856\n",
      "Epoch 34. Time: 0.786, Train loss: 1.851\n",
      "Epoch 35. Time: 0.798, Train loss: 1.847\n",
      "Epoch 36. Time: 0.771, Train loss: 1.842\n",
      "Epoch 37. Time: 0.772, Train loss: 1.837\n",
      "Epoch 38. Time: 0.801, Train loss: 1.832\n",
      "Epoch 39. Time: 0.781, Train loss: 1.826\n",
      "Epoch 40. Time: 0.856, Train loss: 1.821\n",
      "Epoch 41. Time: 0.784, Train loss: 1.816\n",
      "Epoch 42. Time: 0.783, Train loss: 1.810\n",
      "Epoch 43. Time: 0.773, Train loss: 1.803\n",
      "Epoch 44. Time: 0.767, Train loss: 1.797\n",
      "Epoch 45. Time: 0.796, Train loss: 1.790\n",
      "Epoch 46. Time: 0.768, Train loss: 1.782\n",
      "Epoch 47. Time: 0.763, Train loss: 1.773\n",
      "Epoch 48. Time: 0.779, Train loss: 1.761\n",
      "Epoch 49. Time: 0.787, Train loss: 1.737\n",
      "Epoch 50. Time: 0.772, Train loss: 1.637\n",
      "Epoch 51. Time: 0.776, Train loss: 1.444\n",
      "Epoch 52. Time: 0.772, Train loss: 1.321\n",
      "Epoch 53. Time: 0.774, Train loss: 1.118\n",
      "Epoch 54. Time: 0.786, Train loss: 0.993\n",
      "Epoch 55. Time: 0.793, Train loss: 0.914\n",
      "Epoch 56. Time: 0.798, Train loss: 0.846\n",
      "Epoch 57. Time: 0.787, Train loss: 0.806\n",
      "Epoch 58. Time: 0.775, Train loss: 0.661\n",
      "Epoch 59. Time: 0.775, Train loss: 0.588\n",
      "Epoch 60. Time: 0.798, Train loss: 0.535\n",
      "Epoch 61. Time: 0.776, Train loss: 0.447\n",
      "Epoch 62. Time: 0.778, Train loss: 0.464\n",
      "Epoch 63. Time: 0.788, Train loss: 0.415\n",
      "Epoch 64. Time: 0.771, Train loss: 0.344\n",
      "Epoch 65. Time: 0.785, Train loss: 0.277\n",
      "Epoch 66. Time: 0.839, Train loss: 0.181\n",
      "Epoch 67. Time: 0.788, Train loss: 0.149\n",
      "Epoch 68. Time: 0.799, Train loss: 0.125\n",
      "Epoch 69. Time: 0.778, Train loss: 0.108\n",
      "Epoch 70. Time: 0.780, Train loss: 0.096\n",
      "Epoch 71. Time: 0.793, Train loss: 0.084\n",
      "Epoch 72. Time: 0.788, Train loss: 0.074\n",
      "Epoch 73. Time: 0.807, Train loss: 0.067\n",
      "Epoch 74. Time: 0.795, Train loss: 0.061\n",
      "Epoch 75. Time: 0.787, Train loss: 0.056\n",
      "Epoch 76. Time: 0.800, Train loss: 0.051\n",
      "Epoch 77. Time: 0.786, Train loss: 0.047\n",
      "Epoch 78. Time: 0.789, Train loss: 0.044\n",
      "Epoch 79. Time: 0.797, Train loss: 0.041\n",
      "Epoch 80. Time: 0.780, Train loss: 0.038\n",
      "Epoch 81. Time: 0.794, Train loss: 0.036\n",
      "Epoch 82. Time: 0.778, Train loss: 0.034\n",
      "Epoch 83. Time: 0.787, Train loss: 0.032\n",
      "Epoch 84. Time: 0.790, Train loss: 0.031\n",
      "Epoch 85. Time: 0.787, Train loss: 0.029\n",
      "Epoch 86. Time: 0.791, Train loss: 0.028\n",
      "Epoch 87. Time: 0.809, Train loss: 0.026\n",
      "Epoch 88. Time: 0.774, Train loss: 0.025\n",
      "Epoch 89. Time: 0.781, Train loss: 0.024\n",
      "Epoch 90. Time: 0.791, Train loss: 0.023\n",
      "Epoch 91. Time: 0.788, Train loss: 0.022\n",
      "Epoch 92. Time: 0.780, Train loss: 0.021\n",
      "Epoch 93. Time: 0.789, Train loss: 0.021\n",
      "Epoch 94. Time: 0.795, Train loss: 0.020\n",
      "Epoch 95. Time: 0.777, Train loss: 0.019\n",
      "Epoch 96. Time: 0.789, Train loss: 0.019\n",
      "Epoch 97. Time: 0.784, Train loss: 0.018\n",
      "Epoch 98. Time: 0.783, Train loss: 0.017\n",
      "Epoch 99. Time: 0.790, Train loss: 0.017\n"
     ]
    }
   ],
   "source": [
    "for ep in range(100):\n",
    "    start = time.time()\n",
    "    train_loss = 0.\n",
    "    train_passed = 0\n",
    "\n",
    "    for i in range(int(len(X_train) / 100)):\n",
    "        # берём батч в 100 элементов\n",
    "        X_batch = X_train[i * 100:(i + 1) * 100].to(device) # Shape [100, 15]\n",
    "        Y_batch = Y_train[i * 100:(i + 1) * 100].to(device) # Shape [100, 15]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        answers = model.forward(X_batch)              # Shape: [100, 15, 10]\n",
    "        answers_view = answers.view(-1, 10)           # Shape: [100, 15]\n",
    "        Y_view = Y_batch.view(-1)                     # Shape: [1500]\n",
    "        loss = criterion(answers.view(-1, 10), Y_batch.view(-1))\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_passed += 1\n",
    "\n",
    "    print(\"Epoch {}. Time: {:.3f}, Train loss: {:.3f}\".format(ep, time.time() - start, train_loss / train_passed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "32e31b90-53b8-4903-b39a-0c7550a65269",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence(sentence):\n",
    "    answers = model.forward(torch.tensor(sentence).to(device))\n",
    "    probas, indices = answers.topk(1)\n",
    "    return [ind.item() for ind in indices.flatten()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "607a2909-54d4-4427-9b95-0a14d87b2743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 2, 9, 0, 8, 4, 0, 9, 3, 9, 1, 8, 6, 7, 9] [5, 7, 4, 5, 3, 9, 5, 4, 8, 4, 6, 3, 1, 2, 4] [5, 7, 4, 5, 3, 9, 5, 4, 8, 4, 6, 3, 1, 2, 4]\n",
      "[7, 3, 3, 2, 8, 5, 5, 5, 4, 4, 6, 1, 3, 1, 9] [7, 0, 0, 9, 5, 2, 2, 2, 1, 1, 3, 8, 0, 8, 6] [7, 0, 0, 9, 5, 2, 2, 2, 1, 1, 3, 8, 0, 8, 6]\n",
      "[0, 8, 8, 9, 5, 1, 5, 3, 3, 7, 2, 9, 6, 0, 4] [0, 8, 8, 9, 5, 1, 5, 3, 3, 7, 2, 9, 6, 0, 4] [0, 8, 8, 9, 5, 1, 5, 3, 3, 7, 2, 9, 6, 0, 4]\n",
      "[3, 3, 8, 6, 9, 7, 5, 8, 0, 3, 4, 0, 6, 6, 7] [3, 6, 1, 9, 2, 0, 8, 1, 3, 6, 7, 3, 9, 9, 0] [3, 6, 1, 9, 2, 0, 8, 1, 3, 6, 7, 3, 9, 9, 0]\n",
      "[2, 6, 6, 5, 8, 1, 6, 3, 0, 1, 2, 2, 5, 8, 1] [2, 8, 8, 7, 0, 3, 8, 5, 2, 3, 4, 4, 7, 0, 3] [2, 8, 8, 7, 0, 3, 8, 5, 2, 3, 4, 4, 7, 0, 3]\n",
      "[2, 0, 2, 1, 4, 7, 6, 8, 6, 6, 4, 0, 8, 2, 6] [2, 2, 4, 3, 6, 9, 8, 0, 8, 8, 6, 2, 0, 4, 8] [2, 2, 4, 3, 6, 9, 8, 0, 8, 8, 6, 2, 0, 4, 8]\n",
      "[2, 5, 5, 2, 7, 7, 0, 6, 3, 6, 4, 5, 5, 6, 5] [2, 7, 7, 4, 9, 9, 2, 8, 5, 8, 6, 7, 7, 8, 7] [2, 7, 7, 4, 9, 9, 2, 8, 5, 8, 6, 7, 7, 8, 7]\n",
      "[7, 5, 3, 1, 4, 4, 2, 3, 3, 5, 2, 6, 2, 0, 2] [7, 2, 0, 8, 1, 1, 9, 0, 0, 2, 9, 3, 9, 7, 9] [7, 2, 0, 8, 1, 1, 9, 0, 0, 2, 9, 3, 9, 7, 9]\n",
      "[6, 3, 2, 6, 0, 4, 3, 9, 8, 4, 9, 1, 0, 8, 9] [6, 9, 8, 2, 6, 0, 9, 5, 4, 0, 5, 7, 6, 4, 5] [6, 9, 8, 2, 6, 0, 9, 5, 4, 0, 5, 7, 6, 4, 5]\n",
      "[5, 9, 3, 1, 7, 9, 4, 3, 3, 4, 8, 7, 4, 1, 1] [5, 4, 8, 6, 2, 4, 9, 8, 8, 9, 3, 2, 9, 6, 6] [5, 4, 8, 6, 2, 4, 9, 8, 8, 9, 3, 2, 9, 6, 6]\n",
      "Accuracy: 1.000\n"
     ]
    }
   ],
   "source": [
    "TEST_DATASET_LEN = 10\n",
    "X_test = [[random.randint(0, 9) for i in range(SEQUENCE_LEN)] for _ in range(TEST_DATASET_LEN)]\n",
    "Y_test = [get_y_sequence(x) for x in X_test]\n",
    "\n",
    "all = 0\n",
    "right = 0\n",
    "\n",
    "for x, y in zip(X_test, Y_test):\n",
    "    all += 1\n",
    "    answer = generate_sentence(x)\n",
    "    print(x, answer, y)\n",
    "    if answer == y:\n",
    "        right += 1\n",
    "\n",
    "print(f'Accuracy: {right/all:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2e9e3d-3602-44b6-b96d-dcbedd4bfe3f",
   "metadata": {},
   "source": [
    "RNN обучилась за 80 эпох до 100% точности."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0bdf81-8b46-42e2-9cf1-f5901e7783c9",
   "metadata": {},
   "source": [
    "### GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "8fd52d85-49a0-4fab-8f07-174259c67ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=512\n",
    "dataset = torch.utils.data.TensorDataset(X_train, Y_train)\n",
    "data = torch.utils.data.DataLoader(dataset, BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "6ed16d9a-c93b-4d69-bf17-90da9af9d8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, rnnClass, dictionary_size, embedding_size, num_hiddens, num_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_hiddens = num_hiddens\n",
    "        self.embedding = nn.Embedding(dictionary_size, embedding_size)\n",
    "        self.hidden = rnnClass(embedding_size, num_hiddens, batch_first=True)\n",
    "        self.output = nn.Linear(num_hiddens, num_classes)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        out = self.embedding(X)\n",
    "        _, state = self.hidden(out)\n",
    "        predictions = self.output(state[0])#.squeeze())\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "5d90586c-4267-4c61-ade2-14fe3fc38510",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork(nn.GRU, 10, 64, 128, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "45ac07db-58ac-4889-91a5-4c3ad77c7145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (embedding): Embedding(10, 64)\n",
       "  (hidden): GRU(64, 128, batch_first=True)\n",
       "  (output): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f8bda7-b553-4006-9dba-789ebad8b522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def sample(preds):\n",
    "#     softmaxed = torch.softmax(preds, 0)\n",
    "#     probas = torch.distributions.multinomial.Multinomial(1, softmaxed).sample()\n",
    "#     return probas.argmax()\n",
    "\n",
    "# def generate_sequence():\n",
    "#     generated = [random.randint(0, 9) for i in range(SEQUENCE_LEN)]\n",
    "\n",
    "#     for i in range(MAX_LEN):\n",
    "#         x_pred = torch.zeros((1, MAX_LEN), dtype=int)\n",
    "#         for t, char in enumerate(generated[-MAX_LEN:]):\n",
    "#             x_pred[0, t] = CHAR_TO_INDEX[char]\n",
    "\n",
    "#         preds = model.forward(x_pred.to(device))[0].to('cpu')\n",
    "#         next_char = INDEX_TO_CHAR[sample(preds)]\n",
    "#         generated = generated + next_char\n",
    "\n",
    "#     print(generated[:MAX_LEN] + '|' + generated[MAX_LEN:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "5e7464dc-2bde-4bf7-baeb-0fddb2085495",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "f1dc444e-344b-4949-a2fd-ddad7e58a341",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "0D or 1D target tensor expected, multi-target not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[143]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m     10\u001b[39m optimizer.zero_grad()\n\u001b[32m     11\u001b[39m answers = model(X_b)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m loss = \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43manswers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_b\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m train_loss += loss.item()\n\u001b[32m     15\u001b[39m loss.backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/jupiter/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/jupiter/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/jupiter/.venv/lib/python3.12/site-packages/torch/nn/modules/loss.py:1385\u001b[39m, in \u001b[36mCrossEntropyLoss.forward\u001b[39m\u001b[34m(self, input, target)\u001b[39m\n\u001b[32m   1383\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) -> Tensor:\n\u001b[32m   1384\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Runs the forward pass.\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1385\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1386\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1387\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1388\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1389\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1390\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1391\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1392\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/jupiter/.venv/lib/python3.12/site-packages/torch/nn/functional.py:3458\u001b[39m, in \u001b[36mcross_entropy\u001b[39m\u001b[34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[39m\n\u001b[32m   3456\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3457\u001b[39m     reduction = _Reduction.legacy_get_string(size_average, reduce)\n\u001b[32m-> \u001b[39m\u001b[32m3458\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_nn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3459\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3460\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3461\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3462\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3463\u001b[39m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3464\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3465\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: 0D or 1D target tensor expected, multi-target not supported"
     ]
    }
   ],
   "source": [
    "for ep in range(10):\n",
    "    start = time.time()\n",
    "    train_loss = 0.\n",
    "    train_passed = 0\n",
    "\n",
    "    model.train()\n",
    "    for X_b, y_b in data:\n",
    "        y_b = y_b.float()       # Shape 512, 15\n",
    "        X_b, y_b = X_b.to(device), y_b.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        answers = model(X_b)    # Shape 512, 10\n",
    "        loss = criterion(answers, y_b)\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_passed += 1\n",
    "\n",
    "    print(\"Epoch {}. Time: {:.3f}, Train loss: {:.3f}\".format(ep, time.time() - start, train_loss / train_passed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4dc58592-c909-47ad-81f3-40c0a7f56fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence(sentence):\n",
    "    answers = model.forward(torch.tensor(sentence).to(device))\n",
    "    probas, indices = answers.topk(1)\n",
    "    return [ind.item() for ind in indices.flatten()]\n",
    "    # return [ind.item() for ind in answers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0202d5d0-d3e8-4af5-8c6d-d5bbcd0ac37b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 9, 3, 8, 9, 1, 3, 0, 6, 1] [0.07498680055141449, -0.0982784628868103, 0.4880581796169281, -0.4027999937534332, -0.14040526747703552, 0.32545006275177, 0.5708295702934265, 0.04787703603506088, -1.619030475616455, 0.22371217608451843] [5, 4, 8, 3, 4, 6, 8, 5, 1, 6]\n",
      "[4, 9, 7, 6, 1, 9, 0, 1, 8, 8] [0.9444923996925354, 0.5247421860694885, -0.5133309960365295, -4.38349723815918, 0.9919009804725647, 0.6777141094207764, 0.9149038791656494, 1.0781443119049072, 0.1123666912317276, 0.21075138449668884] [4, 3, 1, 0, 5, 3, 4, 5, 2, 2]\n",
      "[9, 6, 9, 0, 4, 4, 9, 5, 2, 7] [0.6963919997215271, 0.10238951444625854, 0.5821854472160339, 0.7114826440811157, -0.3683471381664276, -0.39141035079956055, 0.5761909484863281, -0.10388124734163284, -1.770476222038269, 0.3202802240848541] [9, 5, 8, 9, 3, 3, 8, 4, 1, 6]\n",
      "[5, 6, 8, 6, 7, 3, 5, 6, 0, 2] [0.9244573712348938, -0.45975539088249207, 0.6095533967018127, -0.44103994965553284, 0.10744420439004898, 1.5253572463989258, -4.515803813934326, -0.5593655109405518, 0.9261042475700378, 1.314205288887024] [5, 1, 3, 1, 2, 8, 0, 1, 5, 7]\n",
      "[0, 3, 5, 9, 6, 0, 8, 3, 4, 2] [-5.013969421386719, 0.3662567734718323, 0.8832992911338806, 1.3904979228973389, 1.032900094985962, -4.1661882400512695, 1.4067696332931519, 0.4144684374332428, 0.6526903510093689, -0.022425536066293716] [0, 3, 5, 9, 6, 0, 8, 3, 4, 2]\n",
      "[3, 1, 0, 5, 7, 5, 7, 4, 0, 8] [0.5350484848022461, 0.9773353338241577, 0.5709218978881836, 1.4949101209640503, -3.719276189804077, 1.4848765134811401, -3.7601373195648193, 1.3234459161758423, 0.5461345314979553, -0.8139806389808655] [3, 4, 3, 8, 0, 8, 0, 7, 3, 1]\n",
      "[9, 0, 5, 0, 3, 0, 5, 9, 8, 7] [0.44017675518989563, 0.41047045588493347, -0.32958486676216125, 0.41021794080734253, -1.1303423643112183, 0.36766356229782104, -0.3585953116416931, 0.37888064980506897, 0.2355968952178955, 0.019987042993307114] [9, 9, 4, 9, 2, 9, 4, 8, 7, 6]\n",
      "[8, 8, 1, 4, 6, 6, 2, 9, 1, 8] [0.8135152459144592, 0.7204925417900085, 0.9163630604743958, -0.4221414029598236, 0.11448685079813004, 0.17718292772769928, -4.598691463470459, 0.7627560496330261, 0.8305615782737732, 0.5365789532661438] [8, 6, 9, 2, 4, 4, 0, 7, 9, 6]\n",
      "[1, 3, 2, 4, 7, 3, 4, 8, 4, 1] [-1.6938385963439941, -0.2852504253387451, -0.46026551723480225, -0.04362228512763977, 0.3889297544956207, -0.18111641705036163, -0.037952665239572525, 0.6087534427642822, -0.04435770958662033, -0.8698733448982239] [1, 4, 3, 5, 8, 4, 5, 9, 5, 2]\n",
      "[5, 6, 4, 3, 7, 2, 8, 6, 3, 3] [0.11392340064048767, -1.572879672050476, 0.7443504929542542, 0.5962557792663574, -0.683816134929657, 0.45874592661857605, -0.3863953948020935, -1.3471944332122803, 0.6168026924133301, 0.6540542244911194] [5, 1, 9, 8, 2, 7, 3, 1, 8, 8]\n",
      "Accuracy: 0.000\n"
     ]
    }
   ],
   "source": [
    "SEQUENCE_LEN = 10\n",
    "TEST_DATASET_LEN = 10\n",
    "X_test = [[random.randint(0, 9) for i in range(SEQUENCE_LEN)] for _ in range(TEST_DATASET_LEN)]\n",
    "Y_test = [get_y_sequence(x) for x in X_test]\n",
    "\n",
    "all = 0\n",
    "right = 0\n",
    "\n",
    "for x, y in zip(X_test, Y_test):\n",
    "    all += 1\n",
    "    answer = generate_sentence(x)\n",
    "    print(x, answer, y)\n",
    "    if answer == y:\n",
    "        right += 1\n",
    "\n",
    "print(f'Accuracy: {right/all:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a96788-b32a-45c6-8cd0-52a21b5d31f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
